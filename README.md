# KKBox μμ•… μ¤νΈλ¦¬λ° μ„λΉ„μ¤ μ΄νƒ μμΈ΅ ν”„λ΅μ νΈ

KKBox κµ¬λ…μ μ΄νƒ(Churn) μ—¬λ¶€λ¥Ό μμΈ΅ν•λ” λ¨Έμ‹ λ¬λ‹ / λ”¥λ¬λ‹ νμ΄ν”„λΌμΈμ…λ‹λ‹¤.  
**XGBoost (ML)** μ™€ **ResNet Fine-tuned (DL)** λ‘ λ¨λΈμ„ ν™•μ • μ‚¬μ©ν•©λ‹λ‹¤.

---

## π“ λ””λ ‰ν† λ¦¬ κµ¬μ΅°

```
kkbox_0222/
β”‚
β”β”€β”€ main.py                  # XGBoost νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ§„μ…μ 
β”β”€β”€ dl_main.py               # ResNet λ”¥λ¬λ‹ νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ§„μ…μ 
β”β”€β”€ predict.py               # μ €μ¥λ λ¨λΈ νΈμ¶ ν›„ μμΈ΅ μ‹¤ν–‰ (μ¬ν•™μµ λ¶ν•„μ”)
β”β”€β”€ run_shap.py              # SHAP λ¶„μ„ λ‹¨λ… μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
β”‚
β”β”€β”€ src/
β”‚   β”β”€β”€ data_loader.py       # λ°μ΄ν„° λ΅λ“ (parquet / pkl)
β”‚   β”β”€β”€ preprocessing.py     # κ³µν†µ μ „μ²λ¦¬ & νμƒλ³€μ μƒμ„±
β”‚   β”‚
β”‚   β”β”€β”€ model_train.py       # XGBoost ν•™μµ (Optuna νλ‹ ν¬ν•¨)
β”‚   β”β”€β”€ model_eval.py        # XGBoost ν‰κ°€ & SHAP μ‹κ°ν™”
β”‚   β”‚
β”‚   β”β”€β”€ dl_preprocessing.py  # λ”¥λ¬λ‹μ© Dataset / DataLoader μƒμ„±
β”‚   β”β”€β”€ dl_model.py          # ResNet λ¨λΈ ν΄λμ¤ μ •μ
β”‚   β””β”€β”€ dl_train.py          # λ”¥λ¬λ‹ ν•™μµ / ν‰κ°€ / Fine-tuning ν•¨μ
β”‚
β”β”€β”€ data/
β”‚   β”β”€β”€ kkbox_v3.parquet     # νμ΄ν”„λΌμΈ μ…λ ¥ λ°μ΄ν„° (μ „μ²λ¦¬ μ™„λ£λ³Έ, 97λ§ κ±΄)
β”‚   β”β”€β”€ kkbox_v3.pkl         # parquet λ°±μ—…λ³Έ
β”‚   β””β”€β”€ raw/                 # KKBox μ›λ³Έ CSV νμΌ
β”‚       β”β”€β”€ members_v3.csv
β”‚       β”β”€β”€ train_v2.csv
β”‚       β”β”€β”€ transactions_v2.csv
β”‚       β””β”€β”€ user_logs_v2.csv
β”‚
β”β”€β”€ results/                 # ν•™μµ ν›„ μλ™ μƒμ„±λλ” νμΌλ“¤
β”‚   β”β”€β”€ xgboost_model.pkl    # XGBoost λ¨λΈ μκµ¬ λ³΄κ΄€ (main.py μ‹¤ν–‰ ν›„)
β”‚   β”β”€β”€ resnet_model.pth     # ResNet λ¨λΈ μκµ¬ λ³΄κ΄€ (dl_main.py μ‹¤ν–‰ ν›„)
β”‚   β”β”€β”€ resnet_scaler.pkl    # ResNet μ¤μΌ€μΌλ¬ (μμΈ΅ μ‹ ν•„μ)
β”‚   β”β”€β”€ confusion_matrix.png # νΌλ™ ν–‰λ ¬ μ΄λ―Έμ§€
β”‚   β””β”€β”€ shap_summary.png     # SHAP μ¤‘μ”λ„ μ΄λ―Έμ§€
β”‚
β”β”€β”€ EDA.ipynb                # νƒμƒ‰μ  λ°μ΄ν„° λ¶„μ„ λ…ΈνΈλ¶ (μ°Έκ³ μ© λ³΄κ΄€)
β”β”€β”€ requirements.txt         # μμ΅΄μ„± ν¨ν‚¤μ§€ λ©λ΅
β””β”€β”€ README.md
```

---

## π€ μ‹¤ν–‰ μμ„

### ν™κ²½ μ„¤μ •
```bash
conda activate tp
pip install -r requirements.txt
```

### λ°μ΄ν„° μ¤€λΉ„
νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ „ μ•„λ κ²½λ΅μ— λ°μ΄ν„° νμΌμ΄ μμ–΄μ•Ό ν•©λ‹λ‹¤:
```
data/kkbox_v3.parquet     β† λ°λ“μ‹ ν•„μ” (νμ΄ν”„λΌμΈ μ…λ ¥)
data/raw/*.csv            β† μ›λ³Έ CSV (kkbox_v3.parquet μƒμ„±μ— μ‚¬μ©)
```

### 1. XGBoost νμ΄ν”„λΌμΈ
```bash
python main.py
```
- Optuna 10ν ν•μ΄νΌνλΌλ―Έν„° νƒμƒ‰ β†’ μµμ  λ¨λΈ ν•™μµ
- **ν™•μ • μ„κ³„κ°’: 0.6** (Precision β‰ 0.83, Recall β‰ 0.95)
- ν•™μµ ν›„ λ¨λΈ μ €μ¥: `results/xgboost_model.pkl`
- μ‹κ°ν™” μ €μ¥: `results/confusion_matrix.png`, `results/shap_summary.png`

### 2. ResNet λ”¥λ¬λ‹ νμ΄ν”„λΌμΈ
```bash
python dl_main.py
```
- ν™•μ • ν•μ΄νΌνλΌλ―Έν„°λ΅ ResNet ν•™μµ (Optuna μ¬νƒμƒ‰ μ—†μ, λΉ λ¦„)
- **ν™•μ • μ„κ³„κ°’: 0.8** (Precision β‰ 0.95, Recall β‰ 0.70)
- Early Stopping + LR Scheduler + Gradient Clipping μ μ©
- ν•™μµ μ™„λ£ ν›„ μκµ¬ λ³΄κ΄€: `results/resnet_model.pth`, `results/resnet_scaler.pkl`
- μ¬νƒμƒ‰ μ‹: `dl_main.py`μ Optuna μ£Όμ„ λΈ”λ΅ ν•΄μ  ν›„ μ‹¤ν–‰

### 3. μ €μ¥λ λ¨λΈλ΅ μμΈ΅λ§ μ‹¤ν–‰ (μ¬ν•™μµ λ¶ν•„μ”)
```bash
python predict.py
```
- `main.py`, `dl_main.py` μ‹¤ν–‰ ν›„ μƒμ„±λ νμΌμ„ λ¶λ¬μ™€μ„ μμΈ΅λ§ μν–‰
- λ‘ λ¨λΈμ μμΈ΅ κ²°κ³Όμ™€ λ™μμ¨(μ•™μƒλΈ” μ°Έκ³ )λ„ μ¶λ ¥

### 4. SHAP λ¶„μ„ (μ„ νƒ)
```bash
python run_shap.py
```

---

## π† ν™•μ • λ¨λΈ μ„±λ¥ λΉ„κµ

| μ§€ν‘ | XGBoost | ResNet Fine-tuned |
| :--- | :---: | :---: |
| **μ„κ³„κ°’** | 0.6 | 0.8 |
| **AP Score** | 0.9522 | 0.9450 |
| **Precision** | 0.8319 | 0.9514 |
| **Recall** | 0.9452 | 0.7011 |
| **F1-Score** | 0.8847 | 0.8073 |

### λ¨λΈ μ„ νƒ κ°€μ΄λ“
- **XGBoost μ¶”μ²**: μ΄νƒμλ¥Ό μµλ€ν• λ§μ΄ μ΅κ³  μ‹¶μ„ λ• (Recall μ°μ„ )
- **ResNet μ¶”μ²**: μ •ν™•ν• μ΄νƒμλ§ νƒ€κ²ν…ν•  λ• (Precision μ°μ„ , λ§μΌ€ν… λΉ„μ© μµμ†ν™”)

---

## π”§ μ‘μ—… μ΄λ ¥ μ”μ•½

### λ°μ΄ν„°
- μ›λ³Έ: KKBox κµ¬λ…μ λ΅κ·Έ μ•½ **97λ§ κ±΄**, 24κ° λ³€μ
- νμƒ λ³€μ μƒμ„±: κµ¬λ… κΈ°κ°„, μλ™ κ°±μ‹  μ—¬λ¶€, λ‚μ΄ κ·Έλ£Ή λ“±
- ν΄λμ¤ λ¶κ· ν•: μ΄νƒ(1) μ•½ 7λ§ κ±΄, μ •μƒ(0) μ•½ 71λ§ κ±΄ (μ•½ 10:1)

### ML νμ΄ν”„λΌμΈ (XGBoost)
- Optuna κΈ°λ° ν•μ΄νΌνλΌλ―Έν„° μλ™ νƒμƒ‰ (10ν)
- `scale_pos_weight`λ΅ ν΄λμ¤ λ¶κ· ν• λ€μ‘
- `find_optimal_threshold()`λ΅ F1 κΈ°μ¤€ μµμ  μ„κ³„κ°’ νƒμƒ‰ ν›„ 0.6 ν™•μ •

### DL νμ΄ν”„λΌμΈ (ResNet)
- **λ¨λΈ**: `ChurnResNet` (Residual Block 5κ°, hidden_dim=256)
- **Fine-tuning**: Optunaλ΅ lr + hidden_dim + num_blocks + dropout λ™μ‹ νƒμƒ‰
- **κ³Όμ ν•© λ°©μ§€**:
  - `copy.deepcopy`λ΅ best epoch λ©”λ¨λ¦¬ λ³΄μ΅΄ ν›„ λ³µμ› (νμΌ μ €μ¥ μ—†μ)
  - Early Stopping (patience=5), Gradient Clipping (max_norm=1.0)
  - LR Scheduler (`ReduceLROnPlateau`)
- **ν™•μ • νλΌλ―Έν„°**: lr=0.01121, hidden_dim=256, num_blocks=5, dropout=0.1669
- μ„κ³„κ°’ 0.8 κ³ μ • ν‰κ°€

### μ„λΈ μ‹¤ν— (LSTM - μ°Έκ³ μ©)
- Bidirectional LSTM + Attention κµ¬μ΅° μ‹¤ν—
- WeightedRandomSamplerλ΅ ν΄λμ¤ λ¶κ· ν• λ€μ‘
- AP Score: 0.9363 / μ„κ³„κ°’ 0.9 κΈ°μ¤€ F1: 0.8720
- ν„μ¬ μ½”λ“μ—λ” λ―Έν¬ν•¨ (ν•„μ” μ‹ `dl_model.py`μ `ChurnLSTM` ν΄λμ¤ ν™μ©)

---

## π“¦ μ£Όμ” μμ΅΄μ„±

| ν¨ν‚¤μ§€ | λ²„μ „ | μ©λ„ |
| :--- | :---: | :--- |
| `torch` | 2.10.0 | ResNet λ”¥λ¬λ‹ |
| `xgboost` | 3.2.0 | XGBoost λ¨λΈ |
| `optuna` | 4.7.0 | ν•μ΄νΌνλΌλ―Έν„° νλ‹ |
| `scikit-learn` | 1.8.0 | μ „μ²λ¦¬ / ν‰κ°€ |
| `shap` | 0.50.0 | λ¨λΈ ν•΄μ„ |
| `pandas` | 2.3.3 | λ°μ΄ν„° μ²λ¦¬ |
